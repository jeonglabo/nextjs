{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXcqL9wWbd8z4dVQwE0qLP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YPtVDsvfgMmH"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# 非負値行列分解（NMF）\n","2020年10月15日\n","\n","### 前提条件\n","このポストを理解するためには、以下の内容を事前に理解しておくことを推奨します。\n","\n","- 主成分分析（PCA）\n","- 特異値分解（SVD）\n","- 独立成分分析（ICA）\n","- 勾配降下法（Gradient Descent）\n","\n","※独立成分分析は難解な内容ですが、すべてを理解する必要はありません。主成分分析と勾配降下法については理解しておくことをお勧めします。\n","\n","### NMFの定義\n","非負値行列分解（Non-negative Matrix Factorization, NMF）は、負の値を含まない行列 $ X $ を、負の値を含まない行列 $ W $ と $ H $ の積に分解するアルゴリズムです。\n","\n","数式で表すと、次のようになります。\n","\n","$$\n","X = WH\n","\\tag{1}\n","$$\n","\n","### WとHの意味\n","まず、分解しようとする行列 $ X $ がどのようなものであるかを考えてみましょう。行列 $ X $ はデータセットと考えるとよいでしょう。例えば、行列 $ X $ が $ m \\times n $ 行列であるとしたら、ここで $ m $ はデータサンプルの数（観測の数）、$ n $ は各データサンプルベクトルの次元（データの次元）を表します。\n","\n","#### 図1: データ行列 $ X $ の形\n","\n","一方、行列 $ W $ と $ H $ の次元は、ユーザーの必要に応じて決定できます。ただし、$ W $ の行の数と $ H $ の列の数はそれぞれ $ m $ と $ n $ でなければなりません。\n","\n","例えば、$ p $ 個の特徴量を持つ元のデータセット $ X $ を分解したい場合、$ W $ と $ H $ の次元は次のように決定されます。\n","\n","$$\n","W \\in R^{m \\times p}, \\quad H \\in R^{p \\times n}\n","\\tag{2}, \\tag{3}\n","$$\n","\n","このように分解すると、行列 $ H $ の各行は1つの特徴量になり、行列 $ W $ の各行はそれぞれの特徴量をどの程度組み合わせて使うかについての重みを示します。\n","\n","#### 図2: NMFを利用して分解された行列 $ W $ と $ H $ の形と各行の意味\n","\n","### なぜNMFを使用するのが有用なのか？\n","#### 非負値データは非負値の特徴で説明するのが自然\n","NMFの有用性の1つは、抽出される特徴がすべて非負値であることです。例えば、画像データはすべてピクセルの強度で構成されており、この値は負にはなりません。このような非負値のデータを非負値の特徴で説明するのは自然です。\n","\n","#### 特徴量の独立性を捉えやすい\n","さらに、NMFはデータ構造をよりよく反映できる点でも有用です。PCAやSVDでは特徴量間の直交性が保証されますが、これは必ずしもデータの構造に適合するとは限りません。\n","\n","#### 図3: PCAとNMFの幾何学的な解釈\n","\n","### 必要な予備知識\n","NMFを理解するためには、以下のテクニックを知っておくと役立ちます。\n","\n","- **トレース演算子（Trace）**: 行列の対角成分だけを必要とする場合に使われる演算子です。\n","- **フロベニウスノルム（Frobenius Norm）**: 行列の大きさを測る基準です。\n","\n","### NMFの更新ルール\n","NMFでは次のような更新ルールが使用されます。\n","\n","$$\n","H := H \\circ \\frac{W^T X}{W^T W H}, \\quad W := W \\circ \\frac{X H^T}{W H H^T}\n","\\tag{20}, \\tag{21}\n","$$\n","\n","ここで「$ \\circ $」は要素ごとの積（element-wise product）を示しています。\n","\n","### NMFの適用結果\n","以下は、Yale Extended Face Dataを用いてNMFとPCAで特徴抽出を試みた結果です。\n","\n","#### 図5: NMFで得られた25個の特徴セット\n","#### 図6: PCAで得られた25個の特徴セット\n","\n","NMFで抽出された特徴は、顔の形状や光の方向など、データセットが持つ要素をよく反映しています。\n"],"metadata":{"id":"q-abav3O9qxH"}}]}