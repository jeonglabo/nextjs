{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPt2L0IvHfDkPbNZzHcbI2j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## マハラノビス距離  \n","\n","※ 本ポスティングでは、ベクトルの基本方向を「行ベクトル」として記述しています。詳細については、最初の章「行ベクトルを基本方向とするデータ表現」をご覧ください。  \n","\n","### 前提知識  \n","このポストをよく理解するためには、以下の内容を知っていることが望ましいです。  \n","\n","- 行列と線形変換  \n","- 共分散行列についての詳しい説明が必要な場合は、以下のポストを参照してください。  \n","- 主成分分析（PCA）  \n","\n","### 行ベクトルを基本方向とするデータ表現  \n","数学ではベクトルを表現するとき、通常は列ベクトルを基本の方向として扱います。つまり、任意の $ n $ 次元ベクトル $ x $ は以下のように表現するのが一般的です。  \n","\n","$$\n","\\vec{x} =  \n","\\begin{bmatrix}  \n","x_1 \\\\  \n","x_2 \\\\  \n","\\vdots \\\\  \n","x_n  \n","\\end{bmatrix}  \n","\\tag{1}  \n","$$\n","\n","この場合、行列はベクトルの左側に位置します。任意の $ n \\times n $ 次元行列 $ A $ と $ n $ 次元の列ベクトル $ x $ の積は次のように表されます。  \n","\n","$$\n","Ax \\tag{2}  \n","$$\n","\n","また、列ベクトル同士の内積は転置演算を利用して次のように書けます。任意の $ n $ 次元ベクトル $\\vec{x}$ と $\\vec{y}$ について、  \n","\n","$$\n","\\text{dot}(\\vec{x}, \\vec{y}) = \\vec{x}^T \\vec{y} \\tag{3}  \n","$$\n","\n","しかし、データサイエンスでは理由は不明ですが、通常データの1つを行ベクトルとして扱うことが多いです。すなわち、任意の $ d $ 次元ベクトル $ x $ は次のように書かれます。  \n","\n","$$\n","\\vec{x} = [x_1 \\ x_2 \\ \\ldots \\ x_d] \\tag{4}  \n","$$\n","\n","このようにすると、行列はベクトルの右側に位置します。任意の $ d \\times d $ 次元行列 $ R $ と $ d $ 次元行ベクトル $ x $ の積は以下のように表されます。  \n","\n","$$\n","xR \\tag{5}  \n","$$\n","\n","また、行ベクトル同士の内積も同様に転置演算を使用しますが、転置演算がつくのは右側のベクトルです。つまり、任意の $ d $ 次元行ベクトル $\\vec{x}$ と $\\vec{y}$ について、\n","\n","$$\n","\\text{dot}(\\vec{x}, \\vec{y}) = \\vec{x} \\vec{y}^T \\tag{6}  \n","$$\n","\n","となります。\n","\n","さらに、データサイエンスでは、サンプル数が $ n $ で特徴量の数が $ d $ の場合、データセット $ D $ は $ n \\times d $ 次元の行列として扱うのが一般的です。つまり、サンプルデータが追加されると、行が増えることを意味します。すなわち、1つのデータを「行ベクトル」として扱うのです。\n","\n","このポスティングでは、ベクトルの基本方向が「行ベクトル」と設定されています。\n"],"metadata":{"id":"XBEj030QWhXF"}},{"cell_type":"markdown","source":["## マハラノビス距離\n","\n","### マハラノビス距離とは？\n","\n","マハラノビス距離（Mahalanobis distance）は、データの分布を考慮して、相対的な距離を計算する方法です。通常のユークリッド距離が単純な直線距離を測るのに対して、マハラノビス距離は、データの分布の「文脈」を考慮した距離を測ります。つまり、データの集まり方や分散を考慮して、より適切な距離を計算します。\n","\n","### ユークリッド距離との違い\n","\n","ユークリッド距離は、次のようにして計算します：\n","\n","$$\n","d_E = \\sqrt{(\\vec{x} - \\vec{y})(\\vec{x} - \\vec{y})^T}\n","$$\n","\n","この距離は、単純に2点間の直線距離を計算するものです。しかし、データが他のデータ点とどのような関係にあるか、つまり「文脈」を無視しています。\n","\n","一方で、マハラノビス距離は、データの「文脈」を考慮に入れます。具体的には、データの共分散行列 $\\Sigma$ を使って、その「文脈」を反映した距離を計算します。この共分散行列は、データの広がりや分布を表しており、その逆行列 $\\Sigma^{-1}$ を使うことで、データの分布を「正規化」した形で距離を測ります。\n","\n","### マハラノビス距離の公式\n","\n","マハラノビス距離は次のように表されます：\n","\n","$$\n","d_M = \\sqrt{(\\vec{x} - \\vec{y}) \\Sigma^{-1} (\\vec{x} - \\vec{y})^T}\n","$$\n","\n","ここで：\n","- $\\vec{x}$ と $\\vec{y}$ はベクトルです。\n","- $\\Sigma$ はデータの共分散行列です。\n","- $\\Sigma^{-1}$ は共分散行列の逆行列で、「文脈」を正規化する役割を果たします。\n","\n","### 文脈を考慮した距離\n","\n","データの分布が均一でない場合、同じ距離でもその意味は異なります。例えば、データの密度が高い部分では、わずかな距離でも大きな違いを意味しますが、データがまばらな部分では同じ距離でも小さな違いを意味するかもしれません。マハラノビス距離は、このような分布の違いを反映するため、より適切な距離尺度として使用されます。\n","\n","### 実際の適用\n","\n","例えば、2次元空間でのデータ点の分布が楕円形であるとき、標準偏差を基準にした等高線（標準偏差 1、2、3 など）を描くことで、データの「文脈」を視覚的に理解できます。これらの等高線に基づいて、2点間の距離を再評価すると、文脈を考慮した距離感が得られます。\n","\n","マハラノビス距離は、データの分布を正規化し、文脈に応じた正確な距離感を提供する有用なツールです。\n"],"metadata":{"id":"3yjhGeYWXaDJ"}},{"cell_type":"markdown","source":["申し訳ありません。以下に、日本語で全文を翻訳して提供いたします。\n","\n","---\n","\n","## 共分散行列とその逆行列の意味\n","\n","### 1. iid正規分布サンプルの基礎的な理解\n","\n","データの構造を理解する前に、まずiid（independent and identically distributed: 独立同一分布）正規分布サンプルの性質について理解する必要があります。iidは、データサンプルを抽出する最も単純な方法の1つで、以下の2つの仮定に基づいています。\n","\n","1. **独立性**: 各データサンプルは互いに独立して抽出されている。\n","2. **同一分布**: 各サンプルは同じ確率分布から抽出されている。\n","\n","特に、これらのサンプルが正規分布に従う場合、「独立かつ同一分布の正規乱数変数」と呼びます。\n","\n","### 2. 共分散行列の計算例\n","\n","iidの標準正規分布サンプル $ Z $ があると仮定します。ここで $ Z $ は複数の標準正規分布サンプルを行列形式で積み重ねたものです：\n","\n","$$\n","Z = \\begin{bmatrix} | & | & & | \\\\ z_1 & z_2 & \\cdots & z_d \\\\ | & | & & | \\end{bmatrix}\n","$$\n","\n","各列 $ z_i $ は、平均が0で分散が1のiid標準正規分布サンプルです。したがって、以下の性質が確認できます：\n","\n","- 平均: $ E[z_i] = 0 $ （$ i = 1, 2, \\ldots, d $ に対して）\n","- 共分散の計算:\n","\n","$$\n","E[Z^T Z] = E\\left[\\begin{bmatrix} z_1^T z_1 & z_1^T z_2 & \\cdots & z_1^T z_d \\\\ z_2^T z_1 & z_2^T z_2 & \\cdots & z_2^T z_d \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ z_d^T z_1 & z_d^T z_2 & \\cdots & z_d^T z_d \\end{bmatrix}\\right]\n","$$\n","\n","ここで各対角要素 $ E[z_i^T z_i] $ は $ n $ であり、異なる $ i $ と $ j $ に対して $ E[z_i^T z_j] = 0 $ です。したがって、\n","\n","$$\n","E[Z^T Z] = n I\n","$$\n","\n","この行列において $ I $ は $ d \\times d $ 次元の単位行列です。\n","\n","### 3. 共分散行列の幾何学的な意味\n","\n","共分散行列 $ \\Sigma $ はデータの構造的な形態を理解する上で重要な役割を果たします。この行列の各要素は、データの特徴間の分散および共分散を示し、データの正規化や分析に役立ちます。\n","\n","例えば、$ \\Sigma = \\frac{1}{n} X^T X $ は、与えられたデータの全体的な構造を表現するために使用されます。ここで $ X $ は各特徴の平均を0に移動させたデータセットです。\n","\n","共分散行列の各要素は以下を示します：\n","\n","- 対角要素: 各特徴の分散（データがその軸に沿ってどの程度広がっているか）\n","- 非対角要素: 二つの特徴間の共分散（両者がどの程度同時に変動するか）\n","\n","このように、共分散行列はデータの分布と構造に関する全体的な洞察を提供します。多変量正規分布に関連して、共分散行列はデータの形態を正確に反映し、特にマハラノビス距離などの分析手法において重要な役割を果たします。\n","\n","これらの共分散行列の概念を理解することで、データの特性と文脈を反映したより正確な分析が可能になります。\n","\n"],"metadata":{"id":"cGo5lCKcXlyK"}},{"cell_type":"markdown","source":["### 逆行列とコンテクストの正規化\n","\n","与えられた任意のデータを $x$、その元の形を $z$ とした場合、式 (14) に従うと、与えられたデータの「コンテクスト」を元のデータの形に戻すためには、以下のようにして行うことが可能です。\n","\n","$$\n","z = x R^{-1}\n","$$\n","\n","ここで逆行列を用いた線形変換は、与えられた線形変換 $R$ によって変換されたベクトル空間を元の形に戻すものです。つまり、図10で左から右への変換が元の線形変換 $R$ によるものであれば、逆変換である $R^{-1}$ は図10の右から左への変換を示しています。\n","\n","![図14. 行列Rとその逆行列が意味する線形変換](図のURL)\n","\n","このようにして、元のデータのベクトル空間での原点からの距離 $d_z$ を求めると、以下のようになります。\n","\n","$$\n","d_z = \\sqrt{z z^T} = \\sqrt{(x R^{-1})(x R^{-1})^T}\n","$$\n","\n","$$\n","= \\sqrt{x R^{-1} (R^{-1})^T x^T} = \\sqrt{x (R^T R)^{-1} x^T} = \\sqrt{x \\Sigma^{-1} x^T}\n","$$\n","\n","ここで $\\Sigma$ は、与えられた全データ行列の共分散行列です。\n","\n","同様のプロセスを任意のベクトル $x$ と $y$ 間の距離に適用すると、以下のように修正でき、これは元々説明したマハラノビス距離と同じです。\n","\n","$$\n","\\sqrt{(x - y) \\Sigma^{-1} (x - y)^T}\n","$$\n","\n","---\n","\n","### 等高線と主軸：固有値と固有ベクトル\n","\n","※ 以下の章はやや高度な内容を含んでおり、理解しなくてもマハラノビス距離の大まかな意味には支障ありません。\n","\n","データの「コンテクスト」を理解するためには、標準偏差や「等高線」の話が重要です。マハラノビス距離の理解には、「等高線」の概念が非常に重要な要素となります。\n","\n","まず、図12を再度見てみましょう。図12は、二変数正規分布の代表的な三つの分布形態を示しています。しかし、分布の形が必ずしもこの三種類に限るわけではありません。分布の形がどれだけ回転し、どれだけ引き延ばされたかによって、無数の分布形態が存在し得ます。\n","\n","これらの分布を表現する方法として、「固有値分解」があります。回転の量は固有ベクトルで、引き延ばされた量は固有値で表現されます。\n","\n","共分散行列 $\\Sigma$ を以下のように固有値分解します。\n","\n","$$\n","\\Sigma = Q \\Lambda Q^{-1} = Q \\Lambda Q^T\n","$$\n","\n","共分散行列は常に対称行列であるため、$Q^{-1}$ を $Q^T$ で表すことができます。ここで、$Q$ と $\\Lambda$ はそれぞれ固有ベクトルと固有値を含む行列です。\n","\n","例えば、図12の最初の共分散行列を固有値分解すると、次のような結果が得られます。\n","\n","$$\n","\\begin{bmatrix} 1 & 0.5 \\\\ 0.5 & 1.5 \\end{bmatrix} = \\begin{bmatrix} -0.8507 & 0.5257 \\\\ 0.5257 & 0.8507 \\end{bmatrix} \\begin{bmatrix} 0.6910 & 0 \\\\ 0 & 1.8090 \\end{bmatrix} \\begin{bmatrix} -0.8507 & 0.5257 \\\\ 0.5257 & 0.8507 \\end{bmatrix}^T\n","$$\n","\n","ここで、$Q$ の各列は標準正規分布がどれだけ回転したかを示し、$\\Lambda$ の対角成分は各主成分方向に分布がどれだけ引き延ばされているかを示します。以下の図15で視覚的に確認してみましょう。\n","\n","![図15. 共分散行列の固有値分解の結果](図のURL)\n","\n","この結果を再度説明すると、図3から図5までの内容を数式的に表現したもので、$Q$ の主成分方向は標準偏差を計算する代表的な方向であり、$\\Lambda$ の対角成分は主成分方向での標準偏差を意味します。\n","\n","したがって、主軸上にあるデータを基にマハラノビス距離を理解すると、主軸を元のxy軸に逆回転させ、$\\Lambda$ から得た標準偏差値で正規化した距離を示していると見ることができます。\n","\n"],"metadata":{"id":"Sfhb3klTYSUZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4TBjq3gaIzd"},"outputs":[],"source":[]}]}